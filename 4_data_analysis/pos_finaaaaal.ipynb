{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "introduction"
   },
   "source": [
    "# Job Posting Analysis: Detecting Fraudulent Listings through POS Tagging\n",
    "\n",
    "## Introduction\n",
    "This notebook analyzes job postings to detect potential fraudulent listings by examining Part-of-Speech (POS) tag distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-dependencies"
   },
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-libraries"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data-loading"
   },
   "source": [
    "## Data Loading\n",
    "Upload and load the three datasets containing job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload-files"
   },
   "outputs": [],
   "source": [
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-data"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    real_jobs_df = pd.read_csv(\"real_jobs.csv\")\n",
    "    fake_jobs_df = pd.read_csv(\"fake_jobs.csv\")\n",
    "    llm_refined_df = pd.read_csv(\"llm_refined_fake_posts2.csv\")\n",
    "\n",
    "    print(\"Data loaded successfully:\")\n",
    "    print(f\"- Real jobs: {len(real_jobs_df)} records\")\n",
    "    print(f\"- Fake jobs: {len(fake_jobs_df)} records\")\n",
    "    print(f\"- AI-generated fake jobs: {len(llm_refined_df)} records\")\n",
    "\n",
    "    print(\"\\nPreview of real jobs data:\")\n",
    "    print(real_jobs_df.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pos-analysis"
   },
   "source": [
    "## POS Tagging Analysis\n",
    "\n",
    "### POS Tag Counting Function\n",
    "This function counts POS tags in text using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pos-functions"
   },
   "outputs": [],
   "source": [
    "def get_pos_counts(texts):\n",
    "    \"\"\"Count POS tags in a list of texts using spaCy.\"\"\"\n",
    "    pos_counter = Counter()\n",
    "    valid_texts = [str(text) for text in texts if pd.notna(text)]\n",
    "\n",
    "    for doc in nlp.pipe(valid_texts, disable=[\"ner\", \"parser\"], batch_size=50):\n",
    "        pos_counter.update(\n",
    "            [token.pos_ for token in doc if not token.is_punct and not token.is_space]\n",
    "        )\n",
    "    return pos_counter\n",
    "\n",
    "\n",
    "def normalize(counter):\n",
    "    \"\"\"Normalize counts to frequencies.\"\"\"\n",
    "    total = sum(counter.values())\n",
    "    return {pos: count / total for pos, count in counter.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "extract-descriptions"
   },
   "source": [
    "### Extract and Analyze Descriptions\n",
    "Process the job descriptions from each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "process-texts"
   },
   "outputs": [],
   "source": [
    "# Get descriptions from each dataset\n",
    "real_texts = real_jobs_df[\"description\"].dropna().tolist()\n",
    "fake_texts = fake_jobs_df[\"description\"].dropna().tolist()\n",
    "ai_texts = llm_refined_df[\"description\"].dropna().tolist()\n",
    "\n",
    "# Calculate POS tag frequencies\n",
    "real_pos_counts = get_pos_counts(real_texts)\n",
    "fake_pos_counts = get_pos_counts(fake_texts)\n",
    "ai_pos_counts = get_pos_counts(ai_texts)\n",
    "\n",
    "# Normalize counts\n",
    "real_pos_norm = normalize(real_pos_counts)\n",
    "fake_pos_norm = normalize(fake_pos_counts)\n",
    "ai_pos_norm = normalize(ai_pos_counts)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "pos_data = {\"Real\": real_pos_norm, \"Fake\": fake_pos_norm, \"AI-Fake\": ai_pos_norm}\n",
    "df_pos = pd.DataFrame(pos_data).fillna(0).T\n",
    "\n",
    "print(\"\\nPOS Tag Frequencies:\")\n",
    "print(df_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization"
   },
   "source": [
    "## Visualization\n",
    "Create visual comparison of POS tag distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot-function"
   },
   "outputs": [],
   "source": [
    "def plot_pos_comparison(pos_df):\n",
    "    \"\"\"Plot normalized POS tag distributions for comparison.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    pos_df.plot(kind=\"bar\", stacked=False)\n",
    "    plt.title(\"POS Tag Distribution Comparison Across Job Types\")\n",
    "    plt.xlabel(\"Job Type\")\n",
    "    plt.ylabel(\"Normalized Frequency\")\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.legend(title=\"POS Tags\", bbox_to_anchor=(1.05, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"pos_tag_comparison.png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Generate visualization\n",
    "plot_pos_comparison(df_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save-results"
   },
   "outputs": [],
   "source": [
    "# Save final results\n",
    "df_pos.to_csv(\"pos_tag_results.csv\")\n",
    "print(\"Analysis complete. Results saved to pos_tag_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Job_Posting_Analysis_POS_Tagging.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
