{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a39cbe",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ“Š POS Tagging Analysis\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook supports the study: **Detecting AI-Generated Job Scams: A Human\n",
    "and Machine Perspective**.\n",
    "\n",
    "We aim to explore linguistic differences in job postings using **Part-of-Speech\n",
    "(POS) tagging**, to determine if AI-generated job scams differ from real or\n",
    "human-written fake listings.\n",
    "\n",
    "---\n",
    "\n",
    "## Datasets Used\n",
    "\n",
    "- âœ… Real Job Postings (17,014)\n",
    "- âŒ Human-Written Fake Job Postings (866)\n",
    "- ðŸ¤– AI-Refined Fake Job Postings (866)\n",
    "\n",
    "Each entry includes the job `title`, `description`, and `requirements`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee719ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fb7e8f",
   "metadata": {},
   "source": [
    "### ðŸ“¦ Load & Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b78e8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "real_jobs = pd.read_csv('1_datasets/real_jobs.csv')\n",
    "fake_jobs = pd.read_csv('1_datasets/fake_jobs.csv')\n",
    "llm_refined = pd.read_csv('1_datasets/llm_refined_fake_posts2.csv')\n",
    "\n",
    "\n",
    "# Add source tags and unify text\n",
    "\n",
    "real_jobs['source'] = 'real'\n",
    "real_jobs['text'] = real_jobs[\n",
    "    ['title', 'description', 'requirements']\n",
    "].fillna('').agg(\n",
    "    ' '.join,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "fake_jobs['source'] = 'human_fake'\n",
    "fake_jobs['text'] = fake_jobs[\n",
    "    ['title', 'description', 'requirements']\n",
    "].fillna('').agg(\n",
    "    ' '.join,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "llm_refined['source'] = 'ai_fake'\n",
    "llm_refined['text'] = llm_refined[\n",
    "    ['title', 'refined_description', 'refined_requirements']\n",
    "].fillna('').agg(\n",
    "    ' '.join,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Combine all\n",
    "df = pd.concat([\n",
    "    real_jobs[['text', 'source']],\n",
    "    fake_jobs[['text', 'source']],\n",
    "    llm_refined[['text', 'source']]\n",
    "], ignore_index=True)\n",
    "\n",
    "# Preview combined dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f23cb80",
   "metadata": {},
   "source": [
    "### ðŸ§  POS Tagging\n",
    "We will now apply POS tagging using spaCy to analyze linguistic patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4e6406",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_pos_tags(text):\n",
    "    \n",
    "\n",
    "    doc = nlp(text)\n",
    "    return [token.pos_ for token in doc]\n",
    "\n",
    "# Sample 300 posts from each source for speed\n",
    "sampled_df = (\n",
    "    df.groupby(\"source\")\n",
    "    .apply(lambda x: x.sample(n=300, random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "sampled_df['pos_tags'] = sampled_df['text'].apply(get_pos_tags)\n",
    "sampled_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa26bf5",
   "metadata": {},
   "source": [
    "### ðŸ“ˆ POS Tag Frequency Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7795f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate POS tag frequencies\n",
    "\n",
    "def count_pos(pos_list):\n",
    "\n",
    "    return Counter(pos_list)\n",
    "\n",
    "sampled_df['pos_counts'] = sampled_df['pos_tags'].apply(count_pos)\n",
    "\n",
    "# Convert to long format\n",
    "pos_long = []\n",
    "\n",
    "for _, row in sampled_df.iterrows():\n",
    "    \n",
    "    for tag, count in row['pos_counts'].items():\n",
    "        pos_long.append({'source': row['source'], 'pos': tag, 'count': count})\n",
    "\n",
    "\n",
    "pos_df = pd.DataFrame(pos_long)\n",
    "\n",
    "# Normalize by post\n",
    "pos_df = pos_df.groupby(['source', 'pos'])['count'].mean().reset_index()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=pos_df, x='pos', y='count', hue='source')\n",
    "plt.title(\"Average POS Tag Frequency by Source (Sampled)\")\n",
    "plt.ylabel(\"Average Count per Post\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ecf9c2",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ðŸ§¾ Non-Technical Explanation\n",
    "\n",
    "We used a linguistic technique called **POS tagging** to see how job postings\n",
    "use language differently.\n",
    "\n",
    "- **Real listings** use more **proper nouns** and job-related **verbs**.\n",
    "- **Human fakes** may be less polished, with irregular structure.\n",
    "- **AI fakes** are more consistent and overly clean, showing more **determiners\n",
    "(DET)** and **adjectives (ADJ)** â€” which suggests persuasive language.\n",
    "\n",
    "These trends suggest that AI-generated scams are polished but predictable.\n",
    "\n",
    "### Uncertainty\n",
    "\n",
    "- POS tagging is structural â€” it can miss sarcasm, context, or domain-specific\n",
    "usage.\n",
    "- Dataset imbalance and LLM-refined samples may contain hidden bias.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939c8f6a",
   "metadata": {},
   "source": [
    "\n",
    "## âš™ï¸ Technical Summary\n",
    "\n",
    "- We sampled 300 posts per class to ensure balance and reduce compute time.\n",
    "- We used `spaCy` for POS tagging and `Counter` to count frequencies.\n",
    "- Data was visualized using `Seaborn`.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- Fake data is rare (5%) in the original dataset â€” this affects real-world\n",
    "generalizability.\n",
    "- AI-refined texts were generated with assumptions and may not mimic true\n",
    "scammer behavior.\n",
    "- POS analysis is shallow â€” semantic meaning or intent needs deeper models\n",
    "(like transformer-based analysis).\n",
    "\n",
    "### Alternatives\n",
    "\n",
    "- Token-level classification (NER, syntax trees)\n",
    "- Transformer embeddings + clustering\n",
    "- Stylometry or readability scoring\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c484af",
   "metadata": {},
   "source": [
    "\n",
    "## âœ… Conclusion\n",
    "\n",
    "POS tagging reveals meaningful trends between fake and real listings. Real job\n",
    "descriptions reflect genuine organizational language, while AI-fake ones appear\n",
    "structured and persuasive.\n",
    "\n",
    "This supports our hypothesis: **AI-generated scams differ linguistically**,\n",
    "making POS tagging one of the early-stage tools for detection.\n",
    "\n",
    "> Fraud detection is now a battle between AI-generated content and AI-powered\n",
    "detection â€” and POS tagging provides one lens into that ongoing war.\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
