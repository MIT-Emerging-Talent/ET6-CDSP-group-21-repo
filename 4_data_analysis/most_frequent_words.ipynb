{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8df08e49",
   "metadata": {},
   "source": [
    "The main purpose of this notebook is to check the words in both the raw fake and raw real data, along with the llm-refined version in order to document and visualize the top 15 most frequently used words in all for comparison purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39fc8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# reading the dataset\n",
    "df = pd.read_csv(\"../1_datasets/raw_fake_jobs/fake_job_postings.csv\")\n",
    "\n",
    "# extracting both fraudulent and legitimate jobs\n",
    "fake_jobs = df[df[\"fraudulent\"] == 1].copy()\n",
    "real_jobs = df[df[\"fraudulent\"] == 0].copy()\n",
    "\n",
    "# number of fake and real posts\n",
    "print(\"Total fake jobs detected:\", len(fake_jobs))\n",
    "print(\"Total real jobs detected:\", len(real_jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebba999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words that have high frequency but have no\n",
    "# actual weight so it is better to extract them\n",
    "stopwords = {\n",
    "    \"the\",\n",
    "    \"and\",\n",
    "    \"for\",\n",
    "    \"with\",\n",
    "    \"working\",\n",
    "    \"people\",\n",
    "    \"work\",\n",
    "    \"experience\",\n",
    "    \"company\",\n",
    "    \"skills\",\n",
    "    \"role\",\n",
    "    \"job\",\n",
    "    \"position\",\n",
    "    \"bachelors\",\n",
    "    \"you\",\n",
    "    \"are\",\n",
    "    \"our\",\n",
    "    \"amp\",\n",
    "    \"your\",\n",
    "    \"within\",\n",
    "    \"new\",\n",
    "    \"from\",\n",
    "    \"all\",\n",
    "    \"other\",\n",
    "    \"ability\",\n",
    "    \"more\",\n",
    "    \"that\",\n",
    "    \"including\",\n",
    "    \"time\",\n",
    "    \"years\",\n",
    "    \"have\",\n",
    "    \"looking\",\n",
    "    \"been\",\n",
    "    \"will\",\n",
    "    \"this\",\n",
    "    \"their\",\n",
    "    \"not\",\n",
    "    \"per\",\n",
    "    \"can\",\n",
    "    \"who\",\n",
    "    \"into\",\n",
    "}\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # checks if the input text is Nan, None,\n",
    "    # Nat and returns an empty string incase\n",
    "    # CSV file had empty cells\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    # converts to lowercase\n",
    "    text = str(text).lower()\n",
    "    # removes all characters except for alphabets and spaces\n",
    "    text = \"\".join([char for char in text if char.isalpha() or char == \" \"])\n",
    "\n",
    "    # removes stopwords\n",
    "    words = [word for word in text.split() if word not in stopwords and len(word) > 2]  # noqa: E501\n",
    "\n",
    "    # returns a string and consumes less memory\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "# process all column and combine words\n",
    "all_words_in_fake = []\n",
    "all_words_in_real = []\n",
    "\n",
    "for col in [\n",
    "    \"company_profile\",\n",
    "    \"description\",\n",
    "    \"requirements\",\n",
    "    \"benefits\",\n",
    "]:\n",
    "    fake_text = fake_jobs[col].apply(clean_text).dropna()\n",
    "    real_text = real_jobs[col].apply(clean_text).dropna()\n",
    "    for row in fake_text:\n",
    "        all_words_in_fake.extend(row.split())\n",
    "\n",
    "    for row in real_text:\n",
    "        all_words_in_real.extend(row.split())\n",
    "\n",
    "# check frequency of fake words count\n",
    "fake_words_count = pd.Series(all_words_in_fake).value_counts()\n",
    "\n",
    "# check frequency of real words count\n",
    "real_words_count = pd.Series(all_words_in_real).value_counts()\n",
    "\n",
    "# convert to a DataFrame for fake posts\n",
    "fake_freq_df = pd.DataFrame(fake_words_count).reset_index()\n",
    "fake_freq_df.columns = [\"word\", \"count\"]\n",
    "\n",
    "# convert to a DataFrame for real posts\n",
    "real_freq_df = pd.DataFrame(real_words_count).reset_index()\n",
    "real_freq_df.columns = [\"word\", \"count\"]\n",
    "\n",
    "# save the data in a csv file\n",
    "fake_file_path = (\n",
    "    \"../4_data_analysis/cleaned_most_frequent_words/fake_words_count.csv\"  # noqa: E501\n",
    ")\n",
    "\n",
    "fake_freq_df.to_csv(fake_file_path, index=False)\n",
    "\n",
    "real_file_path = (\n",
    "    \"../4_data_analysis/cleaned_most_frequent_words/real_words_count.csv\"  # noqa: E501\n",
    ")\n",
    "\n",
    "real_freq_df.to_csv(real_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bb5922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file of fake words count\n",
    "fake_df = pd.read_csv(\n",
    "    \"../4_data_analysis/cleaned_most_frequent_words/fake_words_count.csv\"\n",
    ")\n",
    "\n",
    "fake_top15 = fake_df.head(15)\n",
    "\n",
    "# plot histogram\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.barh(fake_top15[\"word\"], fake_top15[\"count\"], color=\"skyblue\")\n",
    "plt.title(\"Top 15 Most Frequent Words in Fraudulent Posts\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# save diagram in a png file\n",
    "fake_dia_file = (\n",
    "    \"../4_data_analysis/cleaned_most_frequent_words/fake_visual_words_count.png\"  # noqa: E501\n",
    ")\n",
    "\n",
    "plt.savefig(fake_dia_file)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff99c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file of real words count\n",
    "real_df = pd.read_csv(\n",
    "    \"../4_data_analysis/cleaned_most_frequent_words/real_words_count.csv\"\n",
    ")\n",
    "\n",
    "real_top15 = real_df.head(15)\n",
    "\n",
    "# plot histogram\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.barh(real_top15[\"word\"], real_top15[\"count\"], color=\"skyblue\")\n",
    "plt.title(\"Top 15 Most Frequent Words in Real Posts\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# save diagram in a png file\n",
    "real_dia_file = (\n",
    "    \"../4_data_analysis/cleaned_most_frequent_words/real_visual_words_count.png\"  # noqa: E501\n",
    ")\n",
    "\n",
    "plt.savefig(real_dia_file)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fda5bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file to check frequency of the words used in the refined LLMs version\n",
    "llm_df = pd.read_json(\"../1_datasets/processed_fake_jobs/original_vs_refined_fakeJobs_descriptions.json\", lines=True)\n",
    "\n",
    "all_words_in_refined_llm = []\n",
    "\n",
    "# using _, as when using .iterrows, it gives the index and data\n",
    "# we're telling it to ignore the index\n",
    "for _, row in llm_df.iterrows():\n",
    "        AI_text = llm_df[\"description\"].apply(clean_text)\n",
    "        \n",
    "        for row in AI_text:\n",
    "                all_words_in_refined_llm.extend(row.split())\n",
    "\n",
    "# check frequency of words\n",
    "refined_llm_words_count = pd.Series(all_words_in_refined_llm).value_counts()\n",
    "\n",
    "# convert it to a DataFrame of two columns\n",
    "refined_llm_freq_df = pd.DataFrame(refined_llm_words_count).reset_index()\n",
    "refined_llm_freq_df.columns = [\"word\", \"count\"]\n",
    "\n",
    "# saving the file\n",
    "refined_llm_file_path = (\"../4_data_analysis/cleaned_most_frequent_words/LLM_refined_words_count.csv\")\n",
    "\n",
    "refined_llm_freq_df.to_csv(refined_llm_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c945c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the top 15 words used by LLM refined posts\n",
    "refined_llm_df = pd.read_csv(\"../4_data_analysis/cleaned_most_frequent_words/LLM_refined_words_count.csv\")\n",
    "\n",
    "refined_llm_top15 = refined_llm_df.head(15)\n",
    "\n",
    "plt.figure(figsize= (8, 4))\n",
    "plt.barh(refined_llm_df.head(15)[\"word\"], refined_llm_df.head(15)[\"count\"], color=\"skyblue\")\n",
    "plt.title(\"Top 15 Most Frequent Words in Fake Refined LLM Posts\")\n",
    "plt.tight_layout\n",
    "\n",
    "refined_llm_dia_file = (\"../4_data_analysis/cleaned_most_frequent_words/LLM_visual_words_count.png\")\n",
    "\n",
    "plt.savefig(refined_llm_dia_file)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54f0620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize all 3 sections together\n",
    "fake_top10 = fake_top15.head(10).rename(columns={\"count\": \"fake\"})\n",
    "real_top10 = real_top15.head(10).rename(columns={\"count\": \"real\"})\n",
    "refined_llm_top10 = refined_llm_top15.head(10).rename(columns={\"count\": \"LLM refined\"})\n",
    "\n",
    "# combining all words from all three sections and dropping duplicates\n",
    "all_top_words= pd.Series(pd.concat([fake_top10[\"word\"], real_top10[\"word\"], refined_llm_top10[\"word\"]])).drop_duplicates()\n",
    "\n",
    "# checking the counts for words that appear in one or two of the three sections from the original DataFrames\n",
    "top_fake= fake_freq_df[fake_freq_df[\"word\"].isin(all_top_words)]\n",
    "top_real= real_freq_df[real_freq_df[\"word\"].isin(all_top_words)]\n",
    "top_llm_refined= refined_llm_freq_df[refined_llm_freq_df[\"word\"].isin(all_top_words)]\n",
    "\n",
    "# merging all words from the three sections in one place\n",
    "combined_words= (\n",
    "  top_fake\n",
    "  .merge(top_real, on=\"word\", how=\"outer\")\n",
    "  .merge(top_llm_refined, on=\"word\", how=\"outer\"))\n",
    "\n",
    "# naming the columns and filling NaN values\n",
    "combined_words.columns=[\"Word\", \"Fake\", \"Real\", \"LLM-Refined\"]\n",
    "combined_words= combined_words.fillna(0)\n",
    "\n",
    "print(\"Shape of the data:\", combined_words.shape)\n",
    "combined_words.head(23)\n",
    "\n",
    "# creating a numeric position for each word in the y-axis\n",
    "y= np.arange(len(combined_words))\n",
    "height= 0.30\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.barh(y+height, combined_words[\"Fake\"], height, label=\"Fake\")\n",
    "plt.barh(y, combined_words[\"Real\"], height, label=\"Real\")\n",
    "plt.barh(y-height, combined_words[\"LLM-Refined\"], height, label=\"LLM-Refined\")\n",
    "\n",
    "plt.yticks(y, combined_words[\"Word\"])\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show\n",
    "\n",
    "# saving the file\n",
    "all_sections_dia_file = (\"../4_data_analysis/cleaned_most_frequent_words/all_sections_words_count.png\")\n",
    "plt.savefig(all_sections_dia_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
