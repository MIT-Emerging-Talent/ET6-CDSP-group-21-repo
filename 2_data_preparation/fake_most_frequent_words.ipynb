{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ec70399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total fake jobs detected: 866\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "#reading the dataset\n",
    "df = pd.read_csv(\"../1_datasets/raw_fake_jobs/fake_job_postings.csv\")\n",
    "\n",
    "#extracting only fraudulent jobs\n",
    "fake_jobs = df[df['fraudulent'] == 1].copy()\n",
    "\n",
    "print(\"Total fake jobs detected:\", len(fake_jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44c3340f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work           1532\n",
      "experience     1313\n",
      "skills         1059\n",
      "amp             947\n",
      "team            771\n",
      "business        676\n",
      "management      674\n",
      "service         607\n",
      "customer        594\n",
      "level           582\n",
      "engineering     575\n",
      "time            570\n",
      "new             545\n",
      "other           535\n",
      "ability         533\n",
      "services        528\n",
      "project         520\n",
      "years           519\n",
      "solutions       508\n",
      "data            493\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#words that have high frequency but have no actual weight so it is better to extract them\n",
    "stopwords = {'the', 'and', 'to', 'for', 'a', 'in', 'is', 'on', 'with', 'company', \n",
    "            'role', 'job', 'position', 'bachelors', 'you', 'are', 'our', 'your', 'am',\n",
    "            'from', 'all', 'that', 'have', 'been', 'will', 'this', 'their', 'not', 'per'\n",
    "            }\n",
    "\n",
    "def clean_text(text):\n",
    "  #checks if the input text is Nan, None, Nat and returns an empty string incase CSV file had empty cells\n",
    "  if pd.isna(text):\n",
    "    return ''\n",
    "  \n",
    "  #converts to lowercase\n",
    "  text = str(text).lower()\n",
    "  #removes all characters except for alphabets and spaces\n",
    "  text = ''.join([char for char in text if char.isalpha() or char == ' '])\n",
    "  \n",
    "  #removes stopwords\n",
    "  words = [word for word in text.split() if word not in stopwords and len(word) > 2]\n",
    "  \n",
    "  return ' '.join(words)  #returns a string and consumes less memory\n",
    "\n",
    "#process all column and combine words\n",
    "all_words = []\n",
    "for col in ['company_profile', 'description', 'requirements', \n",
    "            'benefits', 'telecommuting', 'required_experience']:\n",
    "  cleaned_text = fake_jobs[col].apply(clean_text).dropna()\n",
    "  for row in cleaned_text:\n",
    "    all_words.extend(row.split())\n",
    "  \n",
    "#check frequency\n",
    "word_counts = pd.Series(all_words).value_counts()\n",
    "print(word_counts.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
