{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94bf0f0c",
   "metadata": {},
   "source": [
    "**Fake Jobs Refinement with LLM** \n",
    "\n",
    "This script calls on a large language model (Gemini API)\n",
    "to transform the scam job descriptions in our dataset,\n",
    "to simulate ***\"Fake Job postings written by AI\"*** in alignment\n",
    "with our research objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "execution_count": 27,
   "id": "fc3f44a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "execution_count": 15,
   "id": "f7947d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of fake jobs DataFrame: (500, 6)\n",
      "Fake Jobs Dataset (first 5 rows):\n",
      "   job_id                             title  \\\n",
      "0      99                   IC&E Technician   \n",
      "1     174  Technician Instrument & Controls   \n",
      "2     181                   Sales Executive   \n",
      "3     216           IC&E Technician Mt Poso   \n",
      "4     358         Financing Auto(car) sales   \n",
      "\n",
      "                             location  \\\n",
      "0                   US, , Stocton, CA   \n",
      "1                                  US   \n",
      "2                     PK, SD, Karachi   \n",
      "3  US, CA, Bakersfield, CA / Mt. Poso   \n",
      "4                  US, IL, hazelcrest   \n",
      "\n",
      "                                         description  \\\n",
      "0  IC&amp;E Technician | Bakersfield, CA Mt. Poso...   \n",
      "1  Technician Instrument &amp; ControlsLocation D...   \n",
      "2                                    Sales Executive   \n",
      "3  IC&amp;E Technician | Bakersfield, CA Mt. Poso...   \n",
      "4  If you have experience in financing for auto s...   \n",
      "\n",
      "                                            benefits  fraudulent  \n",
      "0  BENEFITSWhat is offered:Competitive compensati...           1  \n",
      "1  we are a team of almost 8,000 employees who he...           1  \n",
      "2                                    Sales Executive           1  \n",
      "3  BENEFITSWhat is offered:Competitive compensati...           1  \n",
      "4             profit sharingcar allowancecompany car           1  \n"
     ]
    }
   ],
   "source": [
    "# load the fake jobs dataset\n",
    "aegean_fake_jobs_df = pd.read_csv(\n",
    "    \"../1_datasets/cleaned_aegean_fakejobs/aegean_500_fakejobs.csv\"\n",
    ")\n",
    "\n",
    "# print the shape of the DataFrame\n",
    "print(f\"Shape of fake jobs DataFrame: {aegean_fake_jobs_df.shape}\")\n",
    "\n",
    "# display the first few rows of the dataset\n",
    "print(\"Fake Jobs Dataset (first 5 rows):\")\n",
    "print(aegean_fake_jobs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1ff863",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fa89cf9",
   "metadata": {},
   "source": [
    "***Note to the Team***\n",
    "\n",
    "After a careful research on the best way to refine the data without exhausting the API free tier limits, my conclusion is that we have to crowdsource the refinement as a team. What follows below is a split of the 500 dataset into 6 batches for the team members. Please see the fakejobs_to_refine folder for a good understanding of the split.\n",
    "\n",
    "After the batch refinements, I will join the dataset back together, then we can proceed with our NLP analysis on it. DO NOT RUN THE CELL BELOW TO AVOID RESPLITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "943a7309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 84 rows to ../1_datasets/fakejobs_to_refine/batch_84_Justina.csv                (rows 0 to 83)\n",
      "Saved 84 rows to ../1_datasets/fakejobs_to_refine/batch_84_Alaa.csv                (rows 84 to 167)\n",
      "Saved 84 rows to ../1_datasets/fakejobs_to_refine/batch_84_Rouaa.csv                (rows 168 to 251)\n",
      "Saved 84 rows to ../1_datasets/fakejobs_to_refine/batch_84_Geehan.csv                (rows 252 to 335)\n",
      "Saved 84 rows to ../1_datasets/fakejobs_to_refine/batch_84_Aseel.csv                (rows 336 to 419)\n",
      "Saved 80 rows to ../1_datasets/fakejobs_to_refine/batch_84_Majd.csv                (rows 420 to 499)\n",
      "\n",
      "Successfully split 500 jobs into 6 files            in the '../1_datasets/fakejobs_to_refine/' directory.\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into batches for team members\n",
    "# This script will split the dataset into 5 batches of 84 rows each,\n",
    "# with one person (Majd) getting the last batch of 80 rows.\n",
    "\n",
    "\n",
    "OUTPUT_DIR = \"../1_datasets/fakejobs_to_refine/\"\n",
    "BATCH_SIZE = 84  # Number of rows per batch\n",
    "NUM_BATCHES = 6\n",
    "PREFIX = \"batch_84_\"  # Prefix for the output filenames\n",
    "\n",
    "try:\n",
    "    # Select the first 500 rows (or all if less than 500)\n",
    "    df_to_split = aegean_fake_jobs_df.head(BATCH_SIZE * NUM_BATCHES).copy()\n",
    "\n",
    "    # Get the total number of rows to split\n",
    "    total_rows = len(df_to_split)\n",
    "\n",
    "    # List of suffixes for your batches (A, B, C, D, E)\n",
    "    batch_suffixes = [\"Justina\", \"Alaa\", \"Rouaa\", \"Geehan\", \"Aseel\", \"Majd\"]\n",
    "\n",
    "    # Loop to split and save the data\n",
    "    for i in range(NUM_BATCHES):\n",
    "        start_row = i * BATCH_SIZE\n",
    "        end_row = min((i + 1) * BATCH_SIZE, total_rows)\n",
    "\n",
    "        if start_row >= total_rows:\n",
    "            print(f\"Skipping batch {i + 1} as no more rows are available.\")\n",
    "            break\n",
    "\n",
    "        batch_df = df_to_split.iloc[start_row:end_row]\n",
    "\n",
    "        # Use the corresponding suffix\n",
    "        suffix = batch_suffixes[i] if i < len(batch_suffixes) else f\"Extra{i}\"\n",
    "        output_filename = os.path.join(OUTPUT_DIR, f\"{PREFIX}{suffix}.csv\")\n",
    "\n",
    "        # Save the batch to a new CSV file\n",
    "        # index=False prevents pandas from writing the DataFrame\n",
    "        # index as a column\n",
    "        # header=True ensures the column names are written in each file\n",
    "        batch_df.to_csv(output_filename, index=False, header=True)\n",
    "        print(\n",
    "            f\"Saved {len(batch_df)} rows to {output_filename}\\\n",
    "                (rows {start_row} to {end_row - 1})\"\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f\"\\nSuccessfully split {total_rows} jobs into {i + 1} files\\\n",
    "            in the '{OUTPUT_DIR}' directory.\"\n",
    "    )\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\n",
    "        \"Please make sure 'aegean_fake_jobs.csv' is in\\\n",
    "          the 'data/' directory.\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2003f480",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "374b1c1f",
   "metadata": {},
   "source": [
    "# Before running the cells below\n",
    "\n",
    "Read the [Gemini API docs](https://ai.google.dev/gemini-api/docs) and follow the instruction for generating an API key\n",
    "\n",
    "- Then create a .env file in the 2_data_prepartion folder.\n",
    "- in the file add this line API_KEY='your_api_key'\n",
    "- save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a96611",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64edd8d3",
   "metadata": {},
   "source": [
    "**After saving your api key, proceed to run the cell below as it is, no changes needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "execution_count": 28,
   "id": "762cfca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for LLM Refinement\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\n",
    "        \"No API key found. Please set your\\\n",
    "            API key in the .env file.\"\n",
    "    )\n",
    "\n",
    "# Configure the generative AI API\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f62ff",
   "metadata": {},
   "source": [
    "**Run cell as it is**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "execution_count": 29,
   "id": "3c257490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LLM Refinement Prompt\n",
    "\n",
    "# This prompt needs careful engineering!\n",
    "# It's a balance: we make it sound legitimate, but not *too* perfect.\n",
    "# we might need several iterations of prompt engineering.\n",
    "\n",
    "LLM_REFINEMENT_PROMPT = \"\"\"\n",
    "As an expert HR professional, rewrite the following job description.\n",
    "Your goal is to make it sound highly professional, appealing, and legitimate,\n",
    "while subtly incorporating characteristics common in sophisticated yet\n",
    "fraudulent postings.\n",
    "\n",
    "Key objectives:\n",
    "- Improve grammar and vocabulary.\n",
    "- Professionalize vague tasks (e.g., \"data entry\" -> \"information management\").\n",
    "- Eliminate obvious scam flags\n",
    "(e.g., \"send money,\" \"no experience - huge pay\").\n",
    "- Add appealing but potentially exaggerated benefits/responsibilities.\n",
    "- Ensure the application process sounds normal.\n",
    "- Retain the original core job type (e.g., data-related role for 'data entry').\n",
    "\n",
    "Crucially:\n",
    "- DO NOT make it sound *too* perfect; aim for subtle deception.\n",
    "- DO NOT use explicit scam language or mention fraud.\n",
    "\n",
    "Provide ONLY the refined job description. Keep it concise.\n",
    "---\n",
    "{job_description_text}\n",
    "---\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48e9b06",
   "metadata": {},
   "source": [
    "**Run cell as it is**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "execution_count": 30,
   "id": "f832d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to handle LLM calls with retries and exponential backoff ---\n",
    "\n",
    "\n",
    "def call_gemini_with_retries(prompt_text):\n",
    "    \"\"\"\n",
    "    Calls the Gemini API with retries and exponential backoff to handle\n",
    "    rate limits.\n",
    "    \"\"\"\n",
    "    retries = 0\n",
    "    max_retries = 5\n",
    "    base_delay = 2  # seconds\n",
    "    max_delay = 60  # seconds\n",
    "\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = model.generate_content(\n",
    "                prompt_text,\n",
    "            )\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            error_message = str(e).lower()\n",
    "            if (\n",
    "                \"429\" in error_message\n",
    "                or \"rate limit\" in error_message\n",
    "                or \"quota\" in error_message\n",
    "            ):\n",
    "                delay = min(max_delay, base_delay * (2**retries) + random.uniform(0, 1))  # noqa: E501\n",
    "                print(\n",
    "                    f\"  Rate limit/quota error hit. Retrying in {delay:.2f}s..\\\n",
    "                        (Attempt {retries + 1}/{max_retries})\"\n",
    "                )\n",
    "                time.sleep(delay)\n",
    "                retries += 1\n",
    "            else:\n",
    "                print(f\"  An unexpected error occurred during API call: {e}\")\n",
    "                # For other unexpected errors, re-raise to stop processing\n",
    "                # this job\n",
    "                raise\n",
    "\n",
    "    raise Exception(\n",
    "        f\"Max retries ({max_retries}) exceeded for LLM call after\\\n",
    "            multiple failures.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c41819",
   "metadata": {},
   "source": [
    "# Ensure you change to your batch file name below before running cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "execution_count": 31,
   "id": "4f2a260a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading jobs from: ../1_datasets/fakejobs_to_refine\\batch_84_Geehan.csv\n",
      "Loaded 84 jobs for refinement.\n",
      "\n",
      "Starting LLM refinement process...\n",
      "  Refined Job ID: 9749 (1/84)\n",
      "  Refined Job ID: 9750 (2/84)\n",
      "  Refined Job ID: 9752 (3/84)\n",
      "  Refined Job ID: 9754 (4/84)\n",
      "  Refined Job ID: 9757 (5/84)\n",
      "  Pausing for 5 seconds after 5                        requests...\n",
      "  Refined Job ID: 9758 (6/84)\n",
      "  Refined Job ID: 9761 (7/84)\n",
      "  Refined Job ID: 9824 (8/84)\n",
      "  Refined Job ID: 9832 (9/84)\n",
      "  Refined Job ID: 9834 (10/84)\n",
      "  Pausing for 5 seconds after 10                        requests...\n",
      "  Refined Job ID: 9835 (11/84)\n",
      "  Refined Job ID: 9842 (12/84)\n",
      "  Refined Job ID: 9843 (13/84)\n",
      "  Refined Job ID: 9846 (14/84)\n",
      "  Refined Job ID: 9848 (15/84)\n",
      "  Pausing for 5 seconds after 15                        requests...\n",
      "  Refined Job ID: 9879 (16/84)\n",
      "  Refined Job ID: 9969 (17/84)\n",
      "  Refined Job ID: 9972 (18/84)\n",
      "  Refined Job ID: 10113 (19/84)\n",
      "  Refined Job ID: 10220 (20/84)\n",
      "  Pausing for 5 seconds after 20                        requests...\n",
      "  Refined Job ID: 10231 (21/84)\n",
      "  Refined Job ID: 10397 (22/84)\n",
      "  Refined Job ID: 10408 (23/84)\n",
      "  Refined Job ID: 10483 (24/84)\n",
      "  Refined Job ID: 10565 (25/84)\n",
      "  Pausing for 5 seconds after 25                        requests...\n",
      "  Refined Job ID: 10878 (26/84)\n",
      "  Refined Job ID: 10954 (27/84)\n",
      "  Refined Job ID: 10962 (28/84)\n",
      "  Refined Job ID: 11390 (29/84)\n",
      "  Refined Job ID: 11504 (30/84)\n",
      "  Pausing for 5 seconds after 30                        requests...\n",
      "  Refined Job ID: 11508 (31/84)\n",
      "  Refined Job ID: 11516 (32/84)\n",
      "  Refined Job ID: 11539 (33/84)\n",
      "  Refined Job ID: 11542 (34/84)\n",
      "  Refined Job ID: 11543 (35/84)\n",
      "  Pausing for 5 seconds after 35                        requests...\n",
      "  Refined Job ID: 11573 (36/84)\n",
      "  Refined Job ID: 11583 (37/84)\n",
      "  Refined Job ID: 11629 (38/84)\n",
      "  Refined Job ID: 11673 (39/84)\n",
      "  Refined Job ID: 11740 (40/84)\n",
      "  Pausing for 5 seconds after 40                        requests...\n",
      "  Refined Job ID: 11754 (41/84)\n",
      "  Refined Job ID: 11755 (42/84)\n",
      "  Refined Job ID: 11756 (43/84)\n",
      "  Refined Job ID: 11757 (44/84)\n",
      "  Refined Job ID: 11758 (45/84)\n",
      "  Pausing for 5 seconds after 45                        requests...\n",
      "  Refined Job ID: 11760 (46/84)\n",
      "  Refined Job ID: 11761 (47/84)\n",
      "  Refined Job ID: 11763 (48/84)\n",
      "  Refined Job ID: 11767 (49/84)\n",
      "  Refined Job ID: 11769 (50/84)\n",
      "  Pausing for 5 seconds after 50                        requests...\n",
      "  Refined Job ID: 11770 (51/84)\n",
      "  Refined Job ID: 11771 (52/84)\n",
      "  Refined Job ID: 12312 (53/84)\n",
      "  Refined Job ID: 12434 (54/84)\n",
      "  Refined Job ID: 13139 (55/84)\n",
      "  Pausing for 5 seconds after 55                        requests...\n",
      "  Refined Job ID: 13460 (56/84)\n",
      "  Refined Job ID: 14003 (57/84)\n",
      "  Refined Job ID: 14129 (58/84)\n",
      "  Refined Job ID: 14155 (59/84)\n",
      "  Refined Job ID: 14180 (60/84)\n",
      "  Pausing for 5 seconds after 60                        requests...\n",
      "  Refined Job ID: 15150 (61/84)\n",
      "  Refined Job ID: 15200 (62/84)\n",
      "  Refined Job ID: 15265 (63/84)\n",
      "  Refined Job ID: 15929 (64/84)\n",
      "  Refined Job ID: 16803 (65/84)\n",
      "  Pausing for 5 seconds after 65                        requests...\n",
      "  Refined Job ID: 17144 (66/84)\n",
      "  Refined Job ID: 17330 (67/84)\n",
      "  Refined Job ID: 17400 (68/84)\n",
      "  Refined Job ID: 17508 (69/84)\n",
      "  Refined Job ID: 17512 (70/84)\n",
      "  Pausing for 5 seconds after 70                        requests...\n",
      "  Refined Job ID: 17521 (71/84)\n",
      "  Refined Job ID: 17523 (72/84)\n",
      "  Refined Job ID: 17526 (73/84)\n",
      "  Refined Job ID: 17527 (74/84)\n",
      "  Refined Job ID: 17529 (75/84)\n",
      "  Pausing for 5 seconds after 75                        requests...\n",
      "  Refined Job ID: 17531 (76/84)\n",
      "  Refined Job ID: 17535 (77/84)\n",
      "  Refined Job ID: 17536 (78/84)\n",
      "  Refined Job ID: 17539 (79/84)\n",
      "  Refined Job ID: 17540 (80/84)\n",
      "  Pausing for 5 seconds after 80                        requests...\n",
      "  Refined Job ID: 17541 (81/84)\n",
      "  Refined Job ID: 17542 (82/84)\n",
      "  Refined Job ID: 17546 (83/84)\n",
      "  Refined Job ID: 17547 (84/84)\n",
      "\n",
      "LLM refinement complete for ../1_datasets/fakejobs_to_refine\\batch_84_Geehan.csv.\n",
      "Processed 84 jobs successfully out of 84.\n",
      "Results saved to: ../1_datasets/fakejobs_refined/batch_84_Geehan_refined.csv\n"
      "Loading jobs from: ../1_datasets/fakejobs_to_refine\\batch_84_Alaa.csv\n",
      "Loaded 84 jobs for refinement.\n",
      "\n",
      "Starting LLM refinement process...\n",
      "  Refined Job ID: 4184 (1/84)\n",
      "  Refined Job ID: 4267 (2/84)\n",
      "  Refined Job ID: 4316 (3/84)\n",
      "  Refined Job ID: 4345 (4/84)\n",
      "  Refined Job ID: 4347 (5/84)\n",
      "  Pausing for 5 seconds after 5                        requests...\n",
      "  Refined Job ID: 4350 (6/84)\n",
      "  Refined Job ID: 4351 (7/84)\n",
      "  Refined Job ID: 4355 (8/84)\n",
      "  Refined Job ID: 4358 (9/84)\n",
      "  Refined Job ID: 4403 (10/84)\n",
      "  Pausing for 5 seconds after 10                        requests...\n",
      "  Refined Job ID: 4537 (11/84)\n",
      "  Refined Job ID: 4566 (12/84)\n",
      "  Refined Job ID: 4579 (13/84)\n",
      "  Refined Job ID: 4594 (14/84)\n",
      "  Refined Job ID: 4595 (15/84)\n",
      "  Pausing for 5 seconds after 15                        requests...\n",
      "  Refined Job ID: 4600 (16/84)\n",
      "  Refined Job ID: 4606 (17/84)\n",
      "  Refined Job ID: 4608 (18/84)\n",
      "  Refined Job ID: 4651 (19/84)\n",
      "  Refined Job ID: 4661 (20/84)\n",
      "  Pausing for 5 seconds after 20                        requests...\n",
      "  Refined Job ID: 4669 (21/84)\n",
      "  Refined Job ID: 4744 (22/84)\n",
      "  Refined Job ID: 4750 (23/84)\n",
      "  Refined Job ID: 4762 (24/84)\n",
      "  Refined Job ID: 4808 (25/84)\n",
      "  Pausing for 5 seconds after 25                        requests...\n",
      "  Refined Job ID: 4812 (26/84)\n",
      "  Refined Job ID: 4833 (27/84)\n",
      "  Refined Job ID: 4911 (28/84)\n",
      "  Refined Job ID: 4940 (29/84)\n",
      "  Refined Job ID: 4968 (30/84)\n",
      "  Pausing for 5 seconds after 30                        requests...\n",
      "  Refined Job ID: 5026 (31/84)\n",
      "  Refined Job ID: 5027 (32/84)\n",
      "  Refined Job ID: 5059 (33/84)\n",
      "  Refined Job ID: 5074 (34/84)\n",
      "  Refined Job ID: 5116 (35/84)\n",
      "  Pausing for 5 seconds after 35                        requests...\n",
      "  Refined Job ID: 5255 (36/84)\n",
      "  Refined Job ID: 5299 (37/84)\n",
      "  Refined Job ID: 5354 (38/84)\n",
      "  Refined Job ID: 5433 (39/84)\n",
      "  Refined Job ID: 5436 (40/84)\n",
      "  Pausing for 5 seconds after 40                        requests...\n",
      "  Refined Job ID: 5442 (41/84)\n",
      "  Refined Job ID: 5443 (42/84)\n",
      "  Refined Job ID: 5444 (43/84)\n",
      "  Refined Job ID: 5451 (44/84)\n",
      "  Refined Job ID: 5452 (45/84)\n",
      "  Pausing for 5 seconds after 45                        requests...\n",
      "  Refined Job ID: 5473 (46/84)\n",
      "  Refined Job ID: 5496 (47/84)\n",
      "  Refined Job ID: 5499 (48/84)\n",
      "  Refined Job ID: 5503 (49/84)\n",
      "  Refined Job ID: 5505 (50/84)\n",
      "  Pausing for 5 seconds after 50                        requests...\n",
      "  Refined Job ID: 5506 (51/84)\n",
      "  Refined Job ID: 5507 (52/84)\n",
      "  Refined Job ID: 5511 (53/84)\n",
      "  Refined Job ID: 5512 (54/84)\n",
      "  Refined Job ID: 5514 (55/84)\n",
      "  Pausing for 5 seconds after 55                        requests...\n",
      "  Refined Job ID: 5517 (56/84)\n",
      "  Refined Job ID: 5519 (57/84)\n",
      "  Refined Job ID: 5520 (58/84)\n",
      "  Refined Job ID: 5521 (59/84)\n",
      "  Refined Job ID: 5523 (60/84)\n",
      "  Pausing for 5 seconds after 60                        requests...\n",
      "  Refined Job ID: 5524 (61/84)\n",
      "  Refined Job ID: 5527 (62/84)\n",
      "  Refined Job ID: 5563 (63/84)\n",
      "  Refined Job ID: 5568 (64/84)\n",
      "  Refined Job ID: 5573 (65/84)\n",
      "  Pausing for 5 seconds after 65                        requests...\n",
      "  Refined Job ID: 5586 (66/84)\n",
      "  Refined Job ID: 5611 (67/84)\n",
      "  Refined Job ID: 5673 (68/84)\n",
      "  Refined Job ID: 5688 (69/84)\n",
      "  Refined Job ID: 5689 (70/84)\n",
      "  Pausing for 5 seconds after 70                        requests...\n",
      "  Refined Job ID: 5692 (71/84)\n",
      "  Refined Job ID: 5745 (72/84)\n",
      "  Refined Job ID: 5751 (73/84)\n",
      "  Refined Job ID: 5752 (74/84)\n",
      "  Refined Job ID: 5761 (75/84)\n",
      "  Pausing for 5 seconds after 75                        requests...\n",
      "  Refined Job ID: 5784 (76/84)\n",
      "  Refined Job ID: 5805 (77/84)\n",
      "  Refined Job ID: 5809 (78/84)\n",
      "  Refined Job ID: 5839 (79/84)\n",
      "  Refined Job ID: 5871 (80/84)\n",
      "  Pausing for 5 seconds after 80                        requests...\n",
      "  Refined Job ID: 5927 (81/84)\n",
      "  Refined Job ID: 6057 (82/84)\n",
      "  Refined Job ID: 6058 (83/84)\n",
      "  Refined Job ID: 6059 (84/84)\n",
      "\n",
      "LLM refinement complete for ../1_datasets/fakejobs_to_refine\\batch_84_Alaa.csv.\n",
      "Processed 84 jobs successfully out of 84.\n",
      "Results saved to: ../1_datasets/fakejobs_refined/batch_84_Alaa_refined.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration for This Run ---\n",
    "# IMPORTANT: Each team member MUST change filename to their assigned\n",
    "# batch file!\n",
    "# <--- **TEAM MEMBER: CHANGE THIS TO YOUR BATCH FILE!**\n",

    "INPUT_BATCH_FILENAME = \"batch_84_Geehan.csv\"\n",
    "INPUT_BATCH_FILENAME = \"batch_84_Alaa.csv\"\n",
    "\n",
    "# Base path for datasets (relative to the notebook's location)\n",
    "# The notebook is in 2_data_preparation/\n",
    "# The datasets are in 1_dataset/fakejobs_to_refine/\n",
    "DATASET_BASE_PATH = \"../1_datasets/fakejobs_to_refine\"\n",
    "\n",
    "# Construct the full input file path\n",
    "INPUT_FILE_PATH = os.path.join(DATASET_BASE_PATH, INPUT_BATCH_FILENAME)\n",
    "\n",
    "# Define the output directory (where the refined file will be saved)\n",
    "# This will save the refined files alongside the input batches in\n",
    "# 1_dataset/fakejobs_to_refine/\n",
    "OUTPUT_DIR = \"../1_datasets/fakejobs_refined/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)  # Ensure the output directory exists\n",
    "\n",
    "\n",
    "# --- Main Refinement Logic ---\n",
    "def refine_job_batch(input_filepath, output_dir):\n",
    "    \"\"\"\n",
    "    Loads a batch of job descriptions, refines them using Gemini,\n",
    "    adds a 'refined_description' column, and saves the result to a new file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(input_filepath):\n",
    "        print(f\"Error: Input file not found at '{input_filepath}'\")\n",
    "        # In a notebook, we raise an error to stop execution\n",
    "        raise FileNotFoundError(f\"Input file not found: {input_filepath}\")\n",
    "\n",
    "    # Construct the output filename\n",
    "    # e.g., 'data/batch_100_A.csv' -> 'data/batch_100_A_refined.csv'\n",
    "    base_name = os.path.basename(input_filepath)\n",
    "    name_without_ext = os.path.splitext(base_name)[0]\n",
    "    output_path = os.path.join(output_dir, f\"{name_without_ext}_refined.csv\")\n",
    "\n",
    "    print(f\"Loading jobs from: {input_filepath}\")\n",
    "    df = pd.read_csv(input_filepath)\n",
    "    print(f\"Loaded {len(df)} jobs for refinement.\")\n",
    "\n",
    "    # Add columns to store results and status\n",
    "    df[\"refined_description\"] = \"\"\n",
    "    df[\"refinement_status\"] = \"Not Processed\"\n",
    "    df[\"refinement_error\"] = \"\"\n",
    "\n",
    "    print(\"\\nStarting LLM refinement process...\")\n",
    "    processed_count = 0\n",
    "    for index, row in df.iterrows():\n",
    "        original_description = row[\"description\"]\n",
    "        job_id = row.get(\n",
    "            \"job_id\", f\"row_{index}\"\n",
    "        )  # Use job_id if available, otherwise row index\n",
    "\n",
    "        current_prompt = LLM_REFINEMENT_PROMPT.format(\n",
    "            job_description_text=original_description\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            refined_text = call_gemini_with_retries(current_prompt)\n",
    "            df.at[index, \"refined_description\"] = refined_text\n",
    "            df.at[index, \"refinement_status\"] = \"Success\"\n",
    "            processed_count += 1\n",
    "            print(f\"  Refined Job ID: {job_id} ({processed_count}/{len(df)})\")\n",
    "\n",
    "            # Introduce controlled delay\n",
    "            if processed_count % 5 == 0:\n",
    "                print(\n",
    "                    f\"  Pausing for 5 seconds after {processed_count}\\\n",
    "                        requests...\"\n",
    "                )\n",
    "                time.sleep(5)\n",
    "            elif processed_count % 25 == 0:\n",
    "                print(\n",
    "                    f\"  Taking a longer break for 20 seconds\\\n",
    "                        after {processed_count} requests...\"\n",
    "                )\n",
    "                time.sleep(20)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error refining Job ID {job_id}: {e}\")\n",
    "            df.at[index, \"refined_description\"] = (\n",
    "                original_description  # Keep original if failed\n",
    "            )\n",
    "            df.at[index, \"refinement_status\"] = \"Failed\"\n",
    "            df.at[index, \"refinement_error\"] = str(e)\n",
    "\n",
    "    # Save the DataFrame with the new 'refined_description' column\n",
    "    # to a new CSV file\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nLLM refinement complete for {input_filepath}.\")\n",
    "    print(f\"Processed {processed_count} jobs successfully out of {len(df)}.\")\n",
    "    print(f\"Results saved to: {output_path}\")\n",
    "\n",
    "\n",
    "# --- Run the refinement process ---\n",
    "if __name__ == \"__main__\":\n",
    "    refine_job_batch(INPUT_FILE_PATH, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "execution_count": 32,
   "id": "6cecca01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Refined DataFrame (first 5 rows):\n",

      "   job_id                              title              location  \\\n",
      "0    9749   Lawn and Maintenance Contractors  US, MD, College Park   \n",
      "1    9750   Lawn and Maintenance Contractors     US, MD, Annapolis   \n",
      "2    9752   Lawn and Maintenance Contractors    US, MD, Hagerstown   \n",
      "3    9754  Property Preservation Field Crews         US, MD, Bowie   \n",
      "4    9757  Property Preservation Field Crews     US, MD, Rockville   \n",
      "\n",
      "                                         description    benefits  fraudulent  \\\n",
      "0  We are looking for a contractors/individual wh...  As per job           1   \n",
      "1  We are looking for a contractors/individual wh...  As per job           1   \n",
      "2  We are looking for a contractors/individual wh...  As per job           1   \n",
      "3  We are looking for a contractors/individual wh...  As per job           1   \n",
      "4  We are looking for a contractors/individual wh...  As per job           1   \n",
      "\n",
      "                                 refined_description refinement_status  \\\n",
      "0  **Residential Property Preservation Specialist...           Success   \n",
      "1  **Independent Field Service Partner - Property...           Success   \n",
      "2  **Independent Field Operations Specialist, Pro...           Success   \n",
      "3  **Property Field Services Specialist (Independ...           Success   \n",
      "4  **Independent Field Operations Contractor – Pr...           Success   \n",
      "   job_id                                              title  \\\n",
      "0    4184         CUSTOMER SERVICES REP( FULL TIME POSITION)   \n",
      "1    4267                    Customer Service Representative   \n",
      "2    4316                  Senior Mechanical Design Engineer   \n",
      "3    4345                                 Principal Engineer   \n",
      "4    4347  Discipline Manager Civil, Structural, Marine, ...   \n",
      "\n",
      "               location                                        description  \\\n",
      "0        US, TX, AUSTIN  DescriptionDUTIES INCLUDE BUT ARE NOT LIMITED ...   \n",
      "1  US, FL, Jacksonville  Benefits company looking to hire several Custo...   \n",
      "2       US, TX, Houston  Corporate overviewAker Solutions is a global p...   \n",
      "3       US, TX, Houston  Corporate overviewAker Solutions is a global p...   \n",
      "4       US, TX, Houston  Corporate overviewAker Solutions is a global p...   \n",
      "\n",
      "                                            benefits  fraudulent  \\\n",
      "0  Competitive compensation package, benefits and...           1   \n",
      "1                            Weekly PayPaid Holidays           1   \n",
      "2  We offer :• Friendly colleagues in an industry...           1   \n",
      "3  We offer• Friendly colleagues in an industry w...           1   \n",
      "4  We offer• Friendly colleagues in an industry w...           1   \n",
      "\n",
      "                                 refined_description refinement_status  \\\n",
      "0  **Client Engagement Specialist - Service Opera...           Success   \n",
      "1  **Client Engagement Specialist - Remote**\\n\\n*...           Success   \n",
      "2  **Senior Design Project Engineer, Subsea Syste...           Success   \n",
      "3  **Principal Engineer, Strategic Solutions**\\n\\...           Success   \n",
      "4  **Aker Solutions: Shaping the Future of Energy...           Success   \n",
      "\n",
      "   refinement_error  \n",
      "0               NaN  \n",
      "1               NaN  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n"
     ]
    }
   ],
   "source": [
    "# load and inspect the refined DataFrame\n",
    "# (ensure you load the correct batch file)\n",
    "filepaths = \"../1_datasets/fakejobs_refined/batch_84_Geehan_refined.csv\"\n",
    "filepaths = \"../1_datasets/fakejobs_refined/batch_84_Alaa_refined.csv\"\n",
    "df_refined = pd.read_csv(filepaths)\n",
    "\n",
    "# Display the first few rows of the refined DataFrame\n",
    "print(\"\\nRefined DataFrame (first 5 rows):\")\n",
    "print(df_refined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "execution_count": 33,
   "id": "d8060ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of original and refined descriptions:\n",
      "                                         description  \\\n",
      "0  We are looking for a contractors/individual wh...   \n",
      "1  We are looking for a contractors/individual wh...   \n",
      "2  We are looking for a contractors/individual wh...   \n",
      "3  We are looking for a contractors/individual wh...   \n",
      "4  We are looking for a contractors/individual wh...   \n",
      "\n",
      "                                 refined_description  \n",
      "0  **Residential Property Preservation Specialist...  \n",
      "1  **Independent Field Service Partner - Property...  \n",
      "2  **Independent Field Operations Specialist, Pro...  \n",
      "3  **Property Field Services Specialist (Independ...  \n",
      "4  **Independent Field Operations Contractor – Pr...  \n"
      "0  DescriptionDUTIES INCLUDE BUT ARE NOT LIMITED ...   \n",
      "1  Benefits company looking to hire several Custo...   \n",
      "2  Corporate overviewAker Solutions is a global p...   \n",
      "3  Corporate overviewAker Solutions is a global p...   \n",
      "4  Corporate overviewAker Solutions is a global p...   \n",
      "\n",
      "                                 refined_description  \n",
      "0  **Client Engagement Specialist - Service Opera...  \n",
      "1  **Client Engagement Specialist - Remote**\\n\\n*...  \n",
      "2  **Senior Design Project Engineer, Subsea Syste...  \n",
      "3  **Principal Engineer, Strategic Solutions**\\n\\...  \n",
      "4  **Aker Solutions: Shaping the Future of Energy...  \n"
     ]
    }
   ],
   "source": [
    "# display the first five rows of decriptions and refined descriptions\n",
    "print(\"\\nFirst 5 rows of original and refined descriptions:\")\n",
    "print(df_refined[[\"description\", \"refined_description\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "execution_count": 34,
   "id": "e06bd0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in 'refinement_status' column:\n",
      "['Success']\n"
     ]
    }
   ],
   "source": [
    "# list the values in the refinement_status column\n",
    "print(\"\\nUnique values in 'refinement_status' column:\")\n",
    "print(df_refined[\"refinement_status\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "execution_count": 35,
   "id": "f3a55331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No errors encountered during refinement.\n"
     ]
    }
   ],
   "source": [
    "# check for any errors in the refinement process\n",
    "if \"refinement_error\" in df_refined.columns:\n",
    "    errors = df_refined[df_refined[\"refinement_error\"] == \"NaN\"]\n",
    "    if not errors.empty:\n",
    "        print(\"\\nErrors encountered during refinement:\")\n",
    "        print(errors[[\"job_id\", \"refinement_error\"]])\n",
    "    else:\n",
    "        print(\"\\nNo errors encountered during refinement.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "execution_count": 36,
   "id": "d3070f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of refined DataFrame: (84, 9)\n",
      "Total jobs refined: 84\n"
     ]
    }
   ],
   "source": [
    "# current shape of the refined DataFrame\n",
    "print(f\"\\nShape of refined DataFrame: {df_refined.shape}\")\n",
    "print(f\"Total jobs refined: {len(df_refined)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
