{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "300907d1",
   "metadata": {},
   "source": [
    "There are legitimate jobs in the **Aegean Fake Job Postings Prediction** dataset. The goal is to extract 30 randomly for NLP analysis and overall comparison with the refined (AI-Generated) fake posts, in order to detect the extent of similarities between human written real posts and AI-Generated fake posts, which mainly aim to simulate real ones in the first place. \n",
    "\n",
    "## Disclaimer\n",
    "\n",
    "We're not 100% sure that the job posts in this dataset were human written. It was collected between 2012 - 2014 but does not state this fact. We'll consider it as human written for research purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062bb83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../1_datasets/raw_fake_jobs/fake_job_postings.csv\")\n",
    "\n",
    "print(\"Shape of the data\", data.shape)\n",
    "\n",
    "# extracting all real posts\n",
    "real_jobs = data[data[\"fraudulent\"] == 0].copy()\n",
    "\n",
    "# checking the number of real posts\n",
    "print(f\"Extracted{data.shape[0]}real jobs.\")\n",
    "\n",
    "# checking the percentage of real jobs and normalize\n",
    "# the frequency to get proportions instead of absolute values\n",
    "print(\n",
    "    f\"Percentage of real jobs:\\\n",
    "    {data['fraudulent'].value_counts(normalize=True)[0] * 100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values\n",
    "print(\"Missing values in the dataset:\")\n",
    "print(real_jobs.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae89d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding columns that are not necessary for NLP analysis\n",
    "dropped_columns = [\n",
    "    \"job_id\",\n",
    "    \"title\",\n",
    "    \"location\",\n",
    "    \"department\",\n",
    "    \"has_company_logo\",\n",
    "    \"industry\",\n",
    "    \"employment_type\",\n",
    "    \"fraudulent\",\n",
    "    \"telecommuting\",\n",
    "    \"has_questions\",\n",
    "    \"required_experience\",\n",
    "    \"required_education\",\n",
    "    \"function\",\n",
    "]\n",
    "\n",
    "real_jobs.drop(columns=dropped_columns, inplace=True, errors=\"ignore\")\n",
    "\n",
    "print(f\"Shape of the dataset after dropping columns:{real_jobs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c8b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows that have NaN values\n",
    "real_jobs.dropna(\n",
    "    subset=[\n",
    "        \"benefits\",\n",
    "        \"requirements\",\n",
    "        \"company_profile\",\n",
    "        \"salary_range\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# data shape after cleaning NaN values\n",
    "print(\n",
    "    f\"Shape of the data after excluding rows with NaN values:\\\n",
    "    {real_jobs.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "946e0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 30 jobs\n",
    "real_jobs.sample(n=30, random_state=42)\n",
    "\n",
    "# saving the file\n",
    "file_path = \"../1_datasets/cleaned_real_jobs/aegean_cleaned_raw_jobs.csv\"\n",
    "\n",
    "real_jobs.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
