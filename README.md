# ![Typing SVG](https://readme-typing-svg.demolab.com?font=Fira+Code&weight=700&pause=1000&color=CF1F4EFF&width=490&lines=DETECTING+AI-GENERATED+JOB+SCAMS;A+HUMAN+AND+MACHINE+PERSPECTIVE)

---

## Project Overview

The digital job market is facing an alarming rise in **sophisticated
fraudulent job postings crafted by advanced generative AI.** As scammers
increasingly leverage powerful AI, traditional detection methods—reliant
on linguistic cues and behavioral red flags—are proving insufficient.

Our study dives deep into the critical intersection of **cybersecurity**,
**human behavior**, and **Natural Language Processing (NLP)**. We pose a
fundamental question:

---

### ![Typing SVG](https://readme-typing-svg.demolab.com?font=Fira+Code&weight=700&pause=1000&color=CF1F4E&width=435&lines=Research+Question)

**CAN HUMANS STILL DISTINGUISH BETWEEN LEGITIMATE AND FRAUDULENT JOB POSTINGS  
WHEN THE SCAM TEXT IS WRITTEN BY ADVANCED AI MODELS?**

---

To address this crucial inquiry, we also investigate:

- How do genuine and AI-generated scam job postings compare linguistically?
- How do job seekers react to the presence and prominence of an automated
  "scam score" or warning signal on job platforms?

---

## Our Approach: A Simulated Job Board Experiment

We are building a **simulated job board** to test how well people can spot
fake job ads, especially when those ads are created by advanced AI. We also
want to see if a simple "scam warning" helps them.

### 1. Crafting Job Postings

- **Real Jobs:** Gathered from top platforms like LinkedIn and Indeed.
- **AI-Enhanced Fake Jobs:** Fake ads rewritten by AI to sound more realistic,
  using tools like Gemini or GPT.

### 2. Testing with Participants

Participants (job seekers) will interact with our job board:

- **Group A:** No warnings.
- **Group B:** Sees a "scam score" (e.g., 7/10).
- **Group C:** Sees a warning icon (⚠️).
- **Group D:** Sees a text warning ("Potential Scam").

They’ll assess each post as *Legitimate* or *Scam*, and report their confidence.

### 3. Analyzing Results

We’ll compare:

- Scam detection accuracy across all groups
- Human vs AI-generated scam detection
- The effect of different warning styles

---

## Ethical Considerations

- Informed consent required
- Option to withdraw at any time
- All data anonymized and stored securely

---

## Limitations

- Some "real" jobs may be undetected scams
- AI-crafted scams may not be perfectly human-like
- Participants may have prior scam awareness bias

---

## Data Processing Pipeline

Our robust pipeline prepares all the data needed for the experiment. It
includes:

- **Extracting Fake Jobs**
- **AI Refining Fake Jobs**
- **Cleaning Real Jobs**

[View All Datasets](https://github.com/MIT-Emerging-Talent/ET6-CDSP-group-21-repo/tree/main/1_datasets)  
 [View Preparation Scripts](https://github.com/MIT-Emerging-Talent/ET6-CDSP-group-21-repo/tree/main/2_data_preparation)

---

## Conclusion: Beyond Filters, a Battle of AIs

Scam detection is no longer just about spotting typos. It’s a fundamental
battle of **AI versus AI**, with human job seekers in the middle.

This research pushes the boundary of traditional detection and seeks new
strategies for staying one step ahead in a deceptive digital world.

---

## Further Project Insights & Our Team

- **Domain Study & Problem Analysis:**  
  [Explore Here](https://github.com/MIT-Emerging-Talent/ET6-CDSP-group-21-repo/tree/main/0_domain_study)

- **Detailed Project Planning:**  
  [Project Plan Doc](https://docs.google.com/document/d/1i1eVjbVNQgU_a4QyH9LMGibSnDSmWRm3lal7s9J1-GM/edit?tab=t.0)

---

## The Hypatia Circle

**"Reserve your right to think, for even to think wrongly is better than not
to think at all."**  
— *Hypatia of Alexandria*

We are **The Hypatia Circle** — a team of six women from Africa and the Middle
East. We are united by a passion for data science and a drive to innovate for
a safer digital job market.

---
